{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Atmospheric River Detection Algorithm ---------------\n",
    "# --------------------------------------------------------------------\n",
    "# Author: Daemon Kennett (2021)\n",
    "# \n",
    "# An Atmospheric River (AR) detection algorithm for global or\n",
    "# regional studies. Note this code will be subject to \n",
    "# amendment and improvement over time.\n",
    "# \n",
    "# The algorithm is a modified version of the Guan & Waliser (2015) method,\n",
    "# implemented in python.\n",
    "#\n",
    "# If you use or adapt this python script please acknowledge the source, \n",
    "# and reference the GitHub repository at:\n",
    "# https://github.com/daemonkennett/ar_detection\n",
    "# \n",
    "# I am always interested in learning more about AR research.\n",
    "# Please contact me at daemonkennett@gmail.com\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Import Modules and Packages --------------------\n",
    "# --------------------------------------------------------------------\n",
    "# Ignore deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Import modules and packages\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import csv\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import geopy.distance\n",
    "import iris\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import os.path\n",
    "from scipy import ndimage\n",
    "from shapely.geometry import Point\n",
    "import skimage\n",
    "from skimage.segmentation import find_boundaries\n",
    "import xarray as xr\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Define Parameters -------------------------\n",
    "# --------------------------------------------------------------------\n",
    "# For the detection algorithm to run successfully, ensure that all \n",
    "# parameters in this cell are accurate.\n",
    "# \n",
    "# Set file directories:\n",
    "# Enter the directory containing this .ipynb script:\n",
    "ar_dir = '/home/daemonkennett/Desktop/ar_detection_algorithm/' \n",
    "# Input data should be included in a subdirectory within the \n",
    "# ar_dir directory, named 'input_data'. The input_data directory \n",
    "# should include a separate IVT .nc file for each month, for both \n",
    "# eastward and northward IVT, using the format 'e-ivt-YYYY-#m' and \n",
    "# 'n-ivt-YYYY-#m' respectively, e.g. 'e-ivt-2021-1.nc'. A land mask\n",
    "# .nc file should also be included in the ar_dir directory. This must\n",
    "# be a .nc file of the same lat/lon shape as the IVT files, with a \n",
    "# single time dimension, and named land_mask.nc\n",
    "input_data_dir = '{}input_data/'.format(ar_dir) # Names input data dir\n",
    "#\n",
    "# The netcdf files should be cropped to the desired lat/lon search \n",
    "# region before running the detection algorithm. This can be done for\n",
    "# example by using ncks from the NCO package. \n",
    "# \n",
    "# Define search dates:\n",
    "years = [2018,2019,2020] # List of years to include\n",
    "months = [1,2,3,4,5,6,7,8,9,10,11,12] # List of months to include\n",
    "# \n",
    "# Set custom parameters:\n",
    "min_ivt = 150  # IVT threshold fixed lower limit (kg m**-1 s**-1)\n",
    "threshold_percentage = 85  # Defines the IVT percentile threshold\n",
    "min_length = 2000  # Minimum length of ARs in km\n",
    "min_aspect = 2  # Minimum length/width ratio\n",
    "min_span = 1000 # Minimum required distance between AR axis start/end points\n",
    "# To include all ARs, not just landfalling ARs, set below value to 0,\n",
    "# otherwise 1.\n",
    "restrict_landfalling = 0\n",
    "# To shorten the algorithm runtime, small objects that can not represent\n",
    "# and AR are automatically discarded. The below value represents the minimum \n",
    "# size required of an AR, by number of grid cells. Enter a reasonable value\n",
    "# depending on the resolution of the input data.\n",
    "min_size = 60 # Minimum Size - Number of Grid Cells\n",
    "# \n",
    "# Data to be output: (include '1' or exclude '0')\n",
    "include_ar_snapshot = 1\n",
    "include_ar_nc_masks = 1\n",
    "include_ar_char_csv = 1\n",
    "include_filtering_data = 1\n",
    "#\n",
    "# The following values must also be set, based on the size and resolution\n",
    "# of the input data.\n",
    "# \n",
    "# Enter the grid resolution of the data in degrees\n",
    "res = 0.25\n",
    "# Ener the input data lat/lon extent\n",
    "max_lat = 90\n",
    "min_lat = -90\n",
    "max_lon = 180\n",
    "min_lon = -180\n",
    "# Enter the number of latitude/longitude grid cells of the input .nc files\n",
    "lon_grid_number = 1440\n",
    "lat_grid_number = 720\n",
    "# Load Landfall Domain\n",
    "land_mask_dir = '{}land_mask.nc'.format(ar_dir) # Names land mask file\n",
    "land_mask = iris.load(land_mask_dir)[0][0]\n",
    "if restrict_landfalling == 0:\n",
    "    land_mask.data = ((land_mask.data * 0) + 1)\n",
    "# Create a mask of the same shape as the input data, to indicate Northern and \n",
    "# Southern Hemispheres (convention 1 for NH and -1 for SH):\n",
    "hemisphere = land_mask.copy() # Copy land mask\n",
    "hemisphere.data[0:360]=1 # Set the range of NH grid values to 1\n",
    "hemisphere.data[361:720]=-1 # Set the range of SH grid values to -1\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Create Directories -------------------------\n",
    "# --------------------------------------------------------------------\n",
    "# This cell creates the subdirectories within the ar_dir directory.\n",
    "if not os.path.exists('{}ivt_thresholds'.format(ar_dir)):\n",
    "    os.makedirs('ivt_thresholds') # The IVT threshold .nc files are \n",
    "# saved within this directory to save repeatedly computing the IVT \n",
    "# thresholds on each seperate run of the algorithm. Note that these \n",
    "# .nc files must be deleted if changes are made to the IVT thresholds.\n",
    "if not os.path.exists('{}ar_snapshots'.format(ar_dir)):\n",
    "    os.makedirs('ar_snapshots') # Contains AR .png snapshots\n",
    "if not os.path.exists('{}ar_masks'.format(ar_dir)):\n",
    "    os.makedirs('ar_masks') # Contains AR shape .nc masks\n",
    "if not os.path.exists('{}ar_axes'.format(ar_dir)):\n",
    "    os.makedirs('ar_axes') # Contains AR axes .nc masks\n",
    "if not os.path.exists('{}landfall_locations'.format(ar_dir)):\n",
    "    os.makedirs('landfall_locations') # Contains max IVT cell .nc masks\n",
    "if not os.path.exists('{}ar_characteristics'.format(ar_dir)):\n",
    "    os.makedirs('ar_characteristics') # Contains AR characteristics csv file\n",
    "with open('{}\\\n",
    "ar_characteristics/ar_characteristics.csv'.format(ar_dir), 'a', newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    thewriter.writerow(['{}'.format('year'), \\\n",
    "                        '{}'.format('month'), \\\n",
    "                        '{}'.format('day'), \\\n",
    "                        '{}'.format('time'), \\\n",
    "                        '{}'.format('label'), \\\n",
    "                        '{}'.format('length'), \\\n",
    "                        '{}'.format('width'), \\\n",
    "                        '{}'.format('mean_ivt'), \\\n",
    "                        '{}'.format('mean_ivt_direction'), \\\n",
    "                        '{}'.format('landfall_ivt'), \\\n",
    "                        '{}'.format('landfall_ivt_direction')])\n",
    "if not os.path.exists('{}filtering_data'.format(ar_dir)):\n",
    "    os.makedirs('filtering_data') # Contains AR algorithm filtering csv\n",
    "with open('{}\\\n",
    "filtering_data/filtering_data.csv'.format(ar_dir), 'a', newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    thewriter.writerow(['{}'.format('year'), \\\n",
    "                        '{}'.format('month'), \\\n",
    "                        '{}'.format('num_ob_landfall'), \\\n",
    "                        '{}'.format('num_ob_size'), \\\n",
    "                        '{}'.format('num_ob_length'), \\\n",
    "                        '{}'.format('num_ob_narrowness'), \\\n",
    "                        '{}'.format('num_ob_poleward_ivt'), \\\n",
    "                        '{}'.format('num_ob_ivt_coherence'), \\\n",
    "                        '{}'.format('num_ob_orientation')])\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Run Detection Algorithm ----------------------\n",
    "# --------------------------------------------------------------------\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        Date = date(year, month, 1)\n",
    "        print('{}-{}'.format(year,month))\n",
    "        # ---------------------------- Load Data -----------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        print('Loading Data')\n",
    "        # Load 1 month of IVT data\n",
    "        n_ivt_cubes = iris.load('{}n-ivt-{}-{}.nc'.format(input_data_dir,(Date).year, (Date).month))\n",
    "        e_ivt_cubes = iris.load('{}e-ivt-{}-{}.nc'.format(input_data_dir,(Date).year, (Date).month))\n",
    "        # Assign cubes to IVT variables\n",
    "        northward_ivt = n_ivt_cubes[0]\n",
    "        eastward_ivt = e_ivt_cubes[0]\n",
    "        # Compute IVT magnitude (kg m**-1 s**-1)\n",
    "        ivt = np.power(np.power(northward_ivt, 2) \n",
    "                       + np.power(eastward_ivt, 2), 1/2)\n",
    "        zero = 0 * ivt[0] # Create zero cube with same shape as IVT data\n",
    "        # Compute ivt direction within each cell\n",
    "        ivt_direction = ivt.copy()\n",
    "        ivt_direction.data = ((np.arctan2(eastward_ivt.data, northward_ivt.data) \n",
    "                               * 180 / np.pi) + 180) % 360\n",
    "        # --------------------------------------------------------------------\n",
    "        # ---------------------------- Sort Data -----------------------------\n",
    "        ivt_list = []\n",
    "        northward_ivt_list = []\n",
    "        eastward_ivt_list = []\n",
    "        ivt_direction_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            ivt_list.append(ivt[i])\n",
    "            northward_ivt_list.append(northward_ivt[i])\n",
    "            eastward_ivt_list.append(eastward_ivt[i])\n",
    "            ivt_direction_list.append(ivt_direction[i])\n",
    "        # ---------------------- Compute IVT Threshold -----------------------\n",
    "        # Calculates percentile IVT over all time steps during 5 month \n",
    "        # period centred on target month (Month +/- 2 months).\n",
    "        # The IVT threshold is defined as the maximum of percentile threshold\n",
    "        # and the fixed lower limit.\n",
    "        print('Computing IVT Thresholds')\n",
    "        def compute_ivt_threshold(year, month):\n",
    "            # Load 5 months of data (Target Month +/- 2 months)\n",
    "            n_ivt_filename1 = '{}n-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=-2)).year, \n",
    "                                                      (Date+relativedelta(months=-2)).month)\n",
    "            n_ivt_filename2 = '{}n-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=-1)).year, \n",
    "                                                      (Date+relativedelta(months=-1)).month)\n",
    "            n_ivt_filename3 = '{}n-ivt-{}-{}.nc'.format(input_data_dir,(Date).year, (Date).month)\n",
    "            n_ivt_filename4 = '{}n-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=+1)).year,\n",
    "                                                      (Date+relativedelta(months=+1)).month)\n",
    "            n_ivt_filename5 = '{}n-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=+2)).year,\n",
    "                                                      (Date+relativedelta(months=+2)).month)\n",
    "            n_ivt_filenames = [n_ivt_filename1, n_ivt_filename2, n_ivt_filename3,\n",
    "                                n_ivt_filename4, n_ivt_filename5]\n",
    "            n_ivt_xrcubes = xr.open_mfdataset(n_ivt_filenames)\n",
    "            xr.Dataset.to_netcdf(n_ivt_xrcubes, 'n_ivt_data.nc')\n",
    "            n_ivt_cubes0 = iris.load('n_ivt_data.nc')\n",
    "            e_ivt_filename1 = '{}e-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=-2)).year, \n",
    "                                                      (Date+relativedelta(months=-2)).month)\n",
    "            e_ivt_filename2 = '{}e-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=-1)).year, \n",
    "                                                      (Date+relativedelta(months=-1)).month)\n",
    "            e_ivt_filename3 = '{}e-ivt-{}-{}.nc'.format(input_data_dir,(Date).year, (Date).month)\n",
    "            e_ivt_filename4 = '{}e-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=+1)).year,\n",
    "                                                      (Date+relativedelta(months=+1)).month)\n",
    "            e_ivt_filename5 = '{}e-ivt-{}-{}.nc'.format(input_data_dir,\n",
    "                                                        (Date+relativedelta(months=+2)).year,\n",
    "                                                      (Date+relativedelta(months=+2)).month)\n",
    "            e_ivt_filenames = [e_ivt_filename1, e_ivt_filename2, e_ivt_filename3,\n",
    "                                e_ivt_filename4, e_ivt_filename5]\n",
    "            e_ivt_xrcubes = xr.open_mfdataset(e_ivt_filenames)\n",
    "            xr.Dataset.to_netcdf(e_ivt_xrcubes, 'e_ivt_data.nc')\n",
    "            e_ivt_cubes0 = iris.load('e_ivt_data.nc')\n",
    "            # Assign cubes to correct variable\n",
    "            northward_ivt_0 = n_ivt_cubes0[0]\n",
    "            eastward_ivt_0 = e_ivt_cubes0[0]\n",
    "            # Compute IVT Magnitude (kg m**-1 s**-1)\n",
    "            ivt_0 = 0 * northward_ivt_0\n",
    "            ivt_0.data = np.power(np.power(northward_ivt_0.data, 2)\n",
    "                           + np.power(eastward_ivt_0.data, 2), 1/2)\n",
    "            zero_0 = 0 * ivt_0[0]\n",
    "            # Compute IVT percentile threshold\n",
    "            ivt_percentile_threshold = ivt_0.collapsed('time',\n",
    "                                                   iris.analysis.PERCENTILE,\n",
    "                                                   percent=threshold_percentage)\n",
    "            # Define IVT lower limit (kg m**-1 s**-1)\n",
    "            ivt_lower_limit = zero_0 + min_ivt\n",
    "            # Compute IVT threshold\n",
    "            ivt_threshold = (iris.analysis.maths.apply_ufunc(\n",
    "                            np.maximum, ivt_percentile_threshold, ivt_lower_limit))\n",
    "            return ivt_threshold\n",
    "        # Save IVT threshold .nc files\n",
    "        if os.path.exists('{}\\\n",
    "ivt_thresholds/ivt_threshold_{}-{}.nc'.format(ar_dir, year, month)) == True:\n",
    "            ivt_threshold_cube_list = iris.load('{}\\\n",
    "ivt_thresholds/ivt_threshold_{}-{}.nc'.format(ar_dir, year, month))\n",
    "            ivt_threshold = ivt_threshold_cube_list[0]\n",
    "        else:\n",
    "            ivt_threshold = compute_ivt_threshold(year, month)\n",
    "            iris.save(ivt_threshold, '{}\\\n",
    "ivt_threshold_{}-{}.nc'.format(ar_dir, year, month))\n",
    "        # --------------------------------------------------------------------\n",
    "        # ------------------------ Identify Objects --------------------------\n",
    "        print('Identifying Objects')\n",
    "        # Identifies contiguous regions of enhanced IVT (Objects).\n",
    "        # Create cube with value 1 if IVT is above threshold, 0 otherwise.\n",
    "        object_mask = (iris.analysis.maths.apply_ufunc(np.greater, \n",
    "                                                       ivt, ivt_threshold))\n",
    "        object_mask.data = object_mask.data.astype(int)\n",
    "        # Create separate Cubes for each time step and compile as List.\n",
    "        object_mask_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            object_mask_list.append(object_mask[i])\n",
    "        # Label Objects and compile as a List.\n",
    "        # The number of Objects identified for each time step is also recorded.\n",
    "        labelled_object_list = []\n",
    "        num_ob_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            label_cube = object_mask_list[i].copy()\n",
    "            label_cube.data, num_ob = ndimage.label(label_cube.data)\n",
    "            labelled_object_list.append(label_cube)\n",
    "            num_ob_list.append(num_ob)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ------------------------- Landfall Check ---------------------------\n",
    "        # Objects that do not overlap the land mask are filtered.\n",
    "        landfall_filter = []\n",
    "        # Load Land Mask\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            Array = land_mask.data * labelled_object_list[i].data\n",
    "            for j in range(num_ob_list[i]):\n",
    "                landfall_check = (j+1) in Array\n",
    "                if landfall_check == False:\n",
    "                    Filter.append(j+1)\n",
    "            landfall_filter.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "        # --------------------------- Size Filter ----------------------------\n",
    "        # Filter small Objects to speed up code run time.\n",
    "        size_filter = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            # Calculate sizes\n",
    "            object_sizes = ndimage.sum(object_mask_list[i].data, \n",
    "                                       labelled_object_list[i].data, \n",
    "                                       list(range(1, num_ob_list[i]+1)))\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if ((j+1) not in landfall_filter[i]):\n",
    "                    if object_sizes[j] > min_size:\n",
    "                        size_check = True\n",
    "                    else:\n",
    "                        size_check = False\n",
    "                    if size_check == False:\n",
    "                        Filter.append(j+1)\n",
    "            size_filter.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "        # -------------------------- Compute Axis ----------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        print('Computing AR Axes')\n",
    "        axis_list = []\n",
    "        axis_coords_list = []\n",
    "        landfall_locations = []\n",
    "        landfall_ivt_magnitudes = []\n",
    "        landfall_ivt_directions = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            # Create Cube of labelled Axis\n",
    "            axis_cube = zero.copy()\n",
    "            step_coords_list = []\n",
    "            landfall_locations_cube = zero.copy()\n",
    "            step_landfall_ivt_magnitudes = []\n",
    "            step_landfall_ivt_directions = []\n",
    "            # Compute Axis of each Object\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i])):\n",
    "                    object_number = zero + (j+1)\n",
    "                    object_mask = (iris.analysis.maths.apply_ufunc(\n",
    "                                  np.equal, \n",
    "                                  labelled_object_list[i], \n",
    "                                  object_number))\n",
    "                    object_ivt = object_mask * ivt_list[i]\n",
    "                    landfall_ivt = object_ivt * land_mask\n",
    "                    # Compute Axis\n",
    "                    new_axis = zero.copy()\n",
    "                    # Max IVT at landfall\n",
    "                    max_ivt_coords = np.where((landfall_ivt.data.max() == \n",
    "                                               landfall_ivt.data) \n",
    "                                             & (landfall_ivt.data > 0))\n",
    "                    max_ivt_coord = (np.array([max_ivt_coords[0][0]]), \n",
    "                                     np.array([max_ivt_coords[1][0]]))\n",
    "                    axis_coords = [max_ivt_coord]\n",
    "                    new_axis.data[max_ivt_coord[0], max_ivt_coord[1]] = 1\n",
    "                    landfall_locations_cube.data = new_axis.data\n",
    "                    step_landfall_ivt_magnitudes.append(ivt_list[i].data[max_ivt_coord[0], \n",
    "                                                                        max_ivt_coord[1]][0])\n",
    "                    step_landfall_ivt_directions.append(ivt_direction_list[i].data[max_ivt_coord[0], \n",
    "                                                                                   max_ivt_coord[1]][0])\n",
    "                    # Search Axis\n",
    "                    while (object_ivt.data[max_ivt_coord[0], max_ivt_coord[1]] > 0).any():\n",
    "                        if ((0 < max_ivt_coord[0][0] < lat_grid_number-1) and \n",
    "                            (0 < max_ivt_coord[1][0] < lon_grid_number-1)):\n",
    "                            object_ivt.data[max_ivt_coord[0], max_ivt_coord[1]] = 0\n",
    "                            # Compute adjacent cells\n",
    "                            adjacent_cells = []\n",
    "                            # N\n",
    "                            north = (np.array([max_ivt_coord[0][0] - 1]), \n",
    "                                     np.array([max_ivt_coord[1][0]]))\n",
    "                            # NE\n",
    "                            north_east = (np.array([max_ivt_coord[0][0] - 1]), \n",
    "                                          np.array([max_ivt_coord[1][0] + 1]))\n",
    "                            # E\n",
    "                            east = (np.array([max_ivt_coord[0][0]]), \n",
    "                                    np.array([max_ivt_coord[1][0] + 1]))\n",
    "                            # SE\n",
    "                            south_east = (np.array([max_ivt_coord[0][0] + 1]), \n",
    "                                          np.array([max_ivt_coord[1][0] + 1]))\n",
    "                            # S\n",
    "                            south = (np.array([max_ivt_coord[0][0] + 1]), \n",
    "                                     np.array([max_ivt_coord[1][0]]))\n",
    "                            # SW\n",
    "                            south_west = (np.array([max_ivt_coord[0][0] + 1]), \n",
    "                                          np.array([max_ivt_coord[1][0] - 1]))\n",
    "                            # W\n",
    "                            west = (np.array([max_ivt_coord[0][0]]), \n",
    "                                    np.array([max_ivt_coord[1][0] - 1]))\n",
    "                            # NW\n",
    "                            north_west = (np.array([max_ivt_coord[0][0] - 1]), \n",
    "                                          np.array([max_ivt_coord[1][0] - 1]))\n",
    "                            # Determine upstream direction\n",
    "                            upstream_direction = ivt_direction[i].data[max_ivt_coord[0], \n",
    "                                                                       max_ivt_coord[1]]\n",
    "                            if ((upstream_direction > 337.5) or (upstream_direction <= 22.5)):\n",
    "                                list_of_new_coord = [north_west, north, north_east]\n",
    "                            elif (22.5 < upstream_direction <= 67.5):\n",
    "                                list_of_new_coord = [north, north_east, east]\n",
    "                            elif (67.5 < upstream_direction <= 112.5):\n",
    "                                list_of_new_coord = [north_east, east, south_east]\n",
    "                            elif (112.5 < upstream_direction <= 157.5):\n",
    "                                list_of_new_coord = [east, south_east, south]\n",
    "                            elif (157.5 < upstream_direction <= 202.5):\n",
    "                                list_of_new_coord = [south_east, south, south_west]\n",
    "                            elif (202.5 < upstream_direction <= 247.5):\n",
    "                                list_of_new_coord = [south, south_west, west]\n",
    "                            elif (247.5 < upstream_direction <= 292.5):\n",
    "                                list_of_new_coord = [south_west, west, north_west]\n",
    "                            elif (292.5 < upstream_direction <= 337.5):\n",
    "                                list_of_new_coord = [west, north_west, north]\n",
    "                            ivt_values = [object_ivt.data[x[0], x[1]] \n",
    "                                          for x in list_of_new_coord]\n",
    "                            index, value = max(enumerate(ivt_values), \n",
    "                                               key=operator.itemgetter(1))\n",
    "                            max_ivt_coord = list_of_new_coord[index]\n",
    "                            axis_coords.append(max_ivt_coord)\n",
    "                            new_axis.data[max_ivt_coord[0], max_ivt_coord[1]] = 1\n",
    "                        else:\n",
    "                            object_ivt.data[max_ivt_coord[0], max_ivt_coord[1]] = 0\n",
    "                    new_axis.data = new_axis.data.copy() * (j + 1)\n",
    "                    axis_cube.data = axis_cube.copy().data + new_axis.data\n",
    "                    step_coords_list.append(axis_coords)\n",
    "                else:\n",
    "                    step_coords_list.append([])\n",
    "                    step_landfall_ivt_magnitudes.append(0)\n",
    "                    step_landfall_ivt_directions.append(0)\n",
    "            landfall_locations.append(landfall_locations_cube)\n",
    "            axis_list.append(axis_cube)\n",
    "            axis_coords_list.append(step_coords_list)\n",
    "            landfall_ivt_magnitudes.append(step_landfall_ivt_magnitudes)\n",
    "            landfall_ivt_directions.append(step_landfall_ivt_directions)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ---------------------- Compute Axis Length -------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        axis_length_list = []\n",
    "        def calc_length(axis_coords):\n",
    "            length = 0\n",
    "            for k in list(range(len(axis_coords)-1)):\n",
    "                lat1=max_lat-(res*np.abs(axis_coords[k][0]))\n",
    "                lon1=min_lon+(res*np.abs(axis_coords[k][1]))\n",
    "                lat2=max_lat-(res*np.abs(axis_coords[k+1][0]))\n",
    "                lon2=min_lon+(res*np.abs(axis_coords[k+1][1]))\n",
    "                coords_1 = (lat1, lon1)\n",
    "                coords_2 = (lat2, lon2)\n",
    "                segment = geopy.distance.distance(coords_1, coords_2).km\n",
    "                length += segment\n",
    "            return length\n",
    "        for i in range(ivt.shape[0]):\n",
    "            # Compute length of each Object\n",
    "            step_length_list = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i])):\n",
    "                    length = calc_length(axis_coords_list[i][j])\n",
    "                    step_length_list.append(length)\n",
    "                else:\n",
    "                    step_length_list.append(0)\n",
    "            axis_length_list.append(step_length_list)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ---------------------- Calculate Surface Areas ---------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        # Surface area is in square kilometres.\n",
    "        object_area_list = []\n",
    "        # Compute surface area of each grid cell\n",
    "        grid_areas = zero.copy()\n",
    "        grid_areas.coord('latitude').guess_bounds()\n",
    "        grid_areas.coord('longitude').guess_bounds()\n",
    "        grid_areas.data = (iris.analysis.cartography.area_weights(grid_areas) \n",
    "                          / (1000**2))\n",
    "        # Compute surface area of Objects\n",
    "        for i in range(ivt.shape[0]):\n",
    "            areas = ndimage.sum(grid_areas.data, \n",
    "                                   labelled_object_list[i].data, \n",
    "                                   list(range(1, num_ob_list[i]+1)))\n",
    "            object_area_list.append(areas)\n",
    "        # --------------------------------------------------------------------\n",
    "        # -------------------------- Calculate Widths ------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        # The Width of an Object is calculated as its surface area divided\n",
    "        # by its length.\n",
    "        object_width_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            widths = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (axis_length_list[i][j] > 0):\n",
    "                    width = object_area_list[i][j] / axis_length_list[i][j]\n",
    "                    widths.append(width)\n",
    "                else:\n",
    "                    width = 0\n",
    "                    widths.append(width)\n",
    "            object_width_list.append(widths)\n",
    "        # --------------------------------------------------------------------\n",
    "        # -------------------------- AR Criteria -----------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        # -------------------- Criterion 1: Length Check ---------------------\n",
    "        print('Length Criterion')\n",
    "        # Filter Objects based on axis length.\n",
    "        filter_list_1 = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i])):\n",
    "                    length_check = (axis_length_list[i][j] > min_length)\n",
    "                    if length_check == False:\n",
    "                        Filter.append(j+1)\n",
    "            filter_list_1.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "\n",
    "        # ------------------ Criterion 2: Narrowness Check -------------------\n",
    "        # Filter Objects based on length/width ratio.\n",
    "        print('Narrowness Criterion')\n",
    "        filter_list_2 = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i]) \n",
    "                    & ((j+1) not in filter_list_1[i])):\n",
    "                    narrowness_check = ((axis_length_list[i][j] \n",
    "                                        / object_width_list[i][j]) > min_aspect)\n",
    "                    if narrowness_check == False:\n",
    "                        Filter.append(j+1)\n",
    "            filter_list_2.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ----------------- Create List of Max IVT Coords --------------------\n",
    "        max_IVT_coords_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            NewList = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (len(axis_coords_list[i][j]) > 0):\n",
    "                    coords_A = axis_coords_list[i][j][0]\n",
    "                else:\n",
    "                    coords_A = (0,0)\n",
    "                NewList.append(coords_A)\n",
    "            max_IVT_coords_list.append(NewList)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ------------ Create List of Object Mean IVT Magnitude --------------\n",
    "        mean_ivt_magnitude_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            NewList = ndimage.mean(ivt_list[i].data, \n",
    "                                   labelled_object_list[i].data, \n",
    "                                   list(range(1, num_ob_list[i]+1)))\n",
    "            mean_ivt_magnitude_list.append(NewList)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ------------ Create List of Object Mean IVT Direction --------------\n",
    "        mean_ivt_direction_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            mean_northward_ivt = ndimage.mean(northward_ivt[i].data, \n",
    "                                              labelled_object_list[i].data, \n",
    "                                              list(range(1, num_ob_list[i]+1)))\n",
    "            mean_eastward_ivt = ndimage.mean(eastward_ivt[i].data, \n",
    "                                             labelled_object_list[i].data, \n",
    "                                             list(range(1, num_ob_list[i]+1)))\n",
    "            NewList = ((np.arctan2(mean_eastward_ivt, mean_northward_ivt) \n",
    "                        * 180 / np.pi) + 180) % 360\n",
    "            mean_ivt_direction_list.append(NewList)\n",
    "        # --------------------------------------------------------------------\n",
    "        # --------------- Create List of Object Orientations -----------------\n",
    "        object_orientation_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            NewList = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (len(axis_coords_list[i][j]) > 0):\n",
    "                    coords_A = axis_coords_list[i][j][0]\n",
    "                    coords_B = axis_coords_list[i][j][-1]\n",
    "                else:\n",
    "                    coords_A = (0,0)\n",
    "                    coords_B = (0,0)\n",
    "                orientation = ((np.arctan2(coords_A[1] - coords_B[1], \n",
    "                                           coords_A[0] - coords_B[0]) \n",
    "                            * 180 / np.pi) + 180) % 360\n",
    "                NewList.append(orientation)\n",
    "            object_orientation_list.append(NewList)\n",
    "        # --------------------------------------------------------------------\n",
    "        # -------- Create List of Distances between Axis Start and End -------\n",
    "        axis_distance_list = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            NewList = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (len(axis_coords_list[i][j]) > 0):\n",
    "                    coords_A = axis_coords_list[i][j][0]\n",
    "                    coords_B = axis_coords_list[i][j][-1]\n",
    "                else:\n",
    "                    coords_A = (0,0)\n",
    "                    coords_B = (0,0)\n",
    "                lat1=max_lat-(res*np.abs(coords_A[0]))\n",
    "                lon1=min_lon+(res*np.abs(coords_A[1]))\n",
    "                lat2=max_lat-(res*np.abs(coords_B[0]))\n",
    "                lon2=min_lon+(res*np.abs(coords_B[1]))\n",
    "                coords_1 = (lat1, lon1)\n",
    "                coords_2 = (lat2, lon2)\n",
    "                axis_distance = geopy.distance.distance(coords_1, coords_2).km\n",
    "                NewList.append(axis_distance)\n",
    "            axis_distance_list.append(NewList)\n",
    "        # --------------------------------------------------------------------\n",
    "        #-------------- Criterion 3: Mean Meridional IVT Check ---------------\n",
    "        # An object is discarded if the mean IVT does not have a poleward \n",
    "        # component > 50 kg m**-1 s**-1.\n",
    "        print('Meridional IVT Criterion')\n",
    "        filter_list_3 = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i]) \n",
    "                    & ((j+1) not in filter_list_1[i]) \n",
    "                    & ((j+1) not in filter_list_2[i])):\n",
    "                    mean_poleward_ivt = (ndimage.mean(northward_ivt_list[i].data * \n",
    "                                                      hemisphere.data, \n",
    "                                                   labelled_object_list[i].data, \n",
    "                                                    j+1))\n",
    "                    mean_meridional_ivt_check = mean_poleward_ivt > 50\n",
    "                    if mean_meridional_ivt_check == False:\n",
    "                        Filter.append(j+1)\n",
    "            filter_list_3.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "        # ---------- Criterion 4: Coherence in IVT Direction Check -----------\n",
    "        # If more than half of the grid cells have IVT deviating more than 45°\n",
    "        # from the object’s mean IVT, the object is filtered.\n",
    "        print('Coherence IVT Direction Criterion')\n",
    "        filter_list_4 = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i]) \n",
    "                    & ((j+1) not in filter_list_1[i])\n",
    "                    & ((j+1) not in filter_list_2[i])\n",
    "                    & ((j+1) not in filter_list_3[i])):\n",
    "                    mean_direction = mean_ivt_direction_list[i][j]\n",
    "                    deviation_from_mean_direction = (iris.analysis.maths.apply_ufunc(\n",
    "                        np.absolute, ivt_direction_list[i] - mean_direction))\n",
    "                    percentage_coherence_ivt_direction = (ndimage.mean(\n",
    "                        np.logical_or(deviation_from_mean_direction.data < 45, \n",
    "                                      deviation_from_mean_direction.data > 315), \n",
    "                        labelled_object_list[i].data, \n",
    "                        j+1))\n",
    "                    coherence_ivt_check = percentage_coherence_ivt_direction > 0.5\n",
    "                    if coherence_ivt_check == False:\n",
    "                        Filter.append(j+1)\n",
    "            filter_list_4.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "        # Criterion 5: Consistency between IVT Direction and Object Orientation\n",
    "        # If object orientation deviates from the mean IVT direction by more than \n",
    "        # 45 degrees, the object is filtered. Object orientation is calculated as\n",
    "        # the angle between the first and last grid cells of the AR axis. Further,\n",
    "        # the distance between the first and last grid cells of the AR axis must be\n",
    "        # greater than 1000 km.\n",
    "        print('Consistent Orientation Criterion')\n",
    "        filter_list_5 = []\n",
    "        for i in range(ivt.shape[0]):\n",
    "            Filter = []\n",
    "            for j in range(num_ob_list[i]):\n",
    "                if (((j+1) not in size_filter[i]) \n",
    "                    & ((j+1) not in landfall_filter[i]) \n",
    "                    & ((j+1) not in filter_list_1[i])\n",
    "                    & ((j+1) not in filter_list_2[i])\n",
    "                    & ((j+1) not in filter_list_3[i])\n",
    "                    & ((j+1) not in filter_list_4[i])):\n",
    "                    mean_direction = mean_ivt_direction_list[i][j]\n",
    "                    object_orientation = object_orientation_list[i][j]\n",
    "                    deviation_from_mean_direction = np.absolute(float(mean_direction)- \n",
    "                                                                float(object_orientation))\n",
    "                    consistent_orientation_check = deviation_from_mean_direction > 45\n",
    "                    axis_distance_check = axis_distance_list[i][j] < min_span\n",
    "                    if (consistent_orientation_check or axis_distance_check) == False:\n",
    "                        Filter.append(j+1)\n",
    "            filter_list_5.append(Filter)\n",
    "        # --------------------------------------------------------------------\n",
    "        #------------------------ Create AR Snapshot -------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        print('Saving Data')\n",
    "        if include_ar_snapshot == 1:\n",
    "            for i in range(ivt.shape[0]):\n",
    "                if num_ob_list[i] > 0:\n",
    "                    Count = 0\n",
    "                    for j in range(num_ob_list[i]):\n",
    "                        if (((j+1) not in size_filter[i]) \n",
    "                        & ((j+1) not in landfall_filter[i]) \n",
    "                        & ((j+1) not in filter_list_1[i])\n",
    "                        & ((j+1) not in filter_list_2[i])\n",
    "                        & ((j+1) not in filter_list_3[i])\n",
    "                        & ((j+1) not in filter_list_4[i])\n",
    "                        & ((j+1) not in filter_list_5[i])):\n",
    "                            Count += 1\n",
    "                            date_text = str(ivt[i].coord('time'))[10:20]\n",
    "                            time_text = str(ivt[i].coord('time'))[21:23]\n",
    "                            lat1=max_lat-(res*np.abs(int(max_IVT_coords_list[i][j][0])))\n",
    "                            lon1=min_lon+(res*np.abs(int(max_IVT_coords_list[i][j][1])))\n",
    "                            AR_coords = (lat1, lon1)\n",
    "                            # Add a matplotlib axes, specifying the display projection\n",
    "                            ax = plt.axes(projection \n",
    "                                          = ccrs.PlateCarree(central_longitude=180+AR_coords[1]))\n",
    "                            ax.set_extent((-50, 50, AR_coords[0]-30, AR_coords[0]+30), \n",
    "                                          crs = ccrs.PlateCarree(central_longitude=180+AR_coords[1]))\n",
    "                            ax.outline_patch.set_visible(False)\n",
    "                            # Add coastlines\n",
    "                            ax.coastlines(resolution='50m', \n",
    "                                          color='black', \n",
    "                                          linewidth=0.5)\n",
    "                            # Plot AR Boundary\n",
    "                            colors2 = [\"#FFFFFF00\", \"#20ff00\"]\n",
    "                            cmap2 = matplotlib.colors.ListedColormap(colors2)\n",
    "                            object_number = zero + (j+1)\n",
    "                            object_mask = (iris.analysis.maths.apply_ufunc(\n",
    "                                          np.equal, \n",
    "                                          labelled_object_list[i], \n",
    "                                          object_number))\n",
    "                            boundary_obj = object_mask.copy()\n",
    "                            iris.plot.contour(boundary_obj, levels=1, linewidths=0.5,\n",
    "                                              cmap=cmap2, zorder=20)\n",
    "                            # Plot IVT contours\n",
    "                            ivt_contour = (iris.plot.contourf(\n",
    "                                ivt[i], levels=np.linspace(250,1500,11), \n",
    "                                cmap=matplotlib.cm.get_cmap('Blues'), \n",
    "                                zorder=0, extend='max'))\n",
    "                            # Plot AR axis\n",
    "                            colors1 = [\"#FFFFFF00\", \"#FFFF00\"]\n",
    "                            cmap1= matplotlib.colors.ListedColormap(colors1)\n",
    "                            axis_obj = axis_list[i].copy()\n",
    "                            axis_obj.data = np.where(axis_obj.data == j + 1, 1, 0)\n",
    "                            iris.plot.contourf(axis_obj, 1, cmap = cmap1, zorder=20)\n",
    "                            # Plot IVT vectors\n",
    "                            uwind = eastward_ivt[i]\n",
    "                            vwind = northward_ivt[i]\n",
    "                            ulon = uwind.coord('longitude')\n",
    "                            vlon = vwind.coord('longitude')\n",
    "                            ulon.points = ulon.points - 180.0\n",
    "                            vlon.points = vlon.points - 180.0\n",
    "                            x = ulon.points\n",
    "                            y = vwind.coord('latitude').points\n",
    "                            u = uwind.data\n",
    "                            v = vwind.data\n",
    "                            plt.quiver(x[::12], y[::12], u[::12,::12], v[::12,::12], \n",
    "                                       pivot='mid', scale = 45000, color='gray', \n",
    "                                       zorder=5, width = 0.001)\n",
    "                            # Plot colorbar\n",
    "                            cbar = plt.colorbar(ivt_contour, shrink = 0.55)\n",
    "                            cbar.set_label('IVT (kg/m/s)', rotation=270, labelpad = 10, fontsize=8)\n",
    "                            # Plot title\n",
    "                            plt.title(\"Atmospheric River Detected at {}-{} UTC\".format(date_text,\n",
    "                                                                                       time_text), \n",
    "                                      fontdict = {'fontsize' : 10})\n",
    "                            # Plot AR statistics\n",
    "                            length = str(round(axis_length_list[i][j], -1))[:-1][:-1]\n",
    "                            width = str(round(object_width_list[i][j], -1))[:-1][:-1]\n",
    "                            mean_ivt_magnitude = (str(round(mean_ivt_magnitude_list[i][j], \n",
    "                                                          0))[:-1][:-1])\n",
    "                            mean_ivt_direction = (str(round(mean_ivt_direction_list[i][j], \n",
    "                                                          1))[:-1][:-1])\n",
    "                            landfall_ivt_magnitude = (str(round(landfall_ivt_magnitudes[i][j], \n",
    "                                                          0))[:-1][:-1])\n",
    "                            landfall_ivt_direction = (str(round(landfall_ivt_directions[i][j], \n",
    "                                                          1))[:-1][:-1])\n",
    "                            textstr = \"Date: {} UTC \\nLength: {} km, Width: {} km\" \\\n",
    "                            \"\\nMean IVT Magnitude: {} kg/m/s, Mean IVT Direction: {}°\" \\\n",
    "                            \"\\nLandfall IVT Magnitude: {} kg/m/s, Landfall IVT Direction: {}°\" \\\n",
    "                            \"\\nObject Boundary: Green, Axis: Yellow\".format(date_text, \n",
    "                                                                            length, \n",
    "                                                                            width, \n",
    "                                                                            mean_ivt_magnitude, \n",
    "                                                                            mean_ivt_direction, \n",
    "                                                                            landfall_ivt_magnitude, \n",
    "                                                                            landfall_ivt_direction)\n",
    "                            # These are matplotlib.patch.Patch properties\n",
    "                            props = dict(boxstyle='Square', facecolor='skyblue', alpha=0.3)\n",
    "                            # Place a text box\n",
    "                            ax.text(0, -0.15, textstr, transform=ax.transAxes, fontsize=6,\n",
    "                                    verticalalignment='top', bbox=props)\n",
    "                            # Save Figure\n",
    "                            plt.savefig('{}\\\n",
    "ar_snapshots/ar_{}-{}-UTC_snapshot_({})'.format(ar_dir, date_text, time_text, Count), \n",
    "                                        dpi=700)\n",
    "                            plt.close(\"all\")\n",
    "            plt.close(\"all\")\n",
    "        # --------------------------------------------------------------------\n",
    "        # --------------------------- Save Data ------------------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        # ------------------------- Save AR Masks ----------------------------\n",
    "        if include_ar_nc_masks == 1:\n",
    "            for i in range(ivt.shape[0]):\n",
    "                date_text = str(ivt[i].coord('time'))[10:20]\n",
    "                time_text = str(ivt[i].coord('time'))[21:23]\n",
    "                if num_ob_list[i] > 0:\n",
    "                    Count = 0\n",
    "                    for j in range(num_ob_list[i]):\n",
    "                        if (((j+1) not in size_filter[i]) \n",
    "                        & ((j+1) not in landfall_filter[i]) \n",
    "                        & ((j+1) not in filter_list_1[i])\n",
    "                        & ((j+1) not in filter_list_2[i])\n",
    "                        & ((j+1) not in filter_list_3[i])\n",
    "                        & ((j+1) not in filter_list_4[i])\n",
    "                        & ((j+1) not in filter_list_5[i])):\n",
    "                            Count += 1\n",
    "                            ar_mask = labelled_object_list[i].copy()\n",
    "                            ar_axes = zero.copy()\n",
    "                            landfall_location = zero.copy()\n",
    "                            ar_mask.data = np.where(ar_mask.data == j + 1, 1, 0)\n",
    "                            iris.save(ar_mask, '{}\\\n",
    "ar_masks/ar_{}-{}-UTC_mask_({}).nc'.format(ar_dir, date_text, time_text, Count))\n",
    "                            iris.save(axis_list[i], '{}\\\n",
    "ar_axes/ar_{}-{}-UTC_axes_({}).nc'.format(ar_dir, date_text, time_text, Count))\n",
    "                            iris.save(landfall_locations[i], '{}\\\n",
    "landfall_locations/ar_{}-{}-UTC_landfall_location_({}).nc'.format(ar_dir, date_text, time_text, Count))\n",
    "        # --------------------------------------------------------------------\n",
    "        # ------------------------ Save AR Statistics ------------------------\n",
    "        # Save AR characteristics as .csv file\n",
    "        if include_ar_char_csv == 1:\n",
    "            for i in range(ivt.shape[0]):\n",
    "                if num_ob_list[i] > 0:\n",
    "                    Count = 0\n",
    "                    for j in range(num_ob_list[i]):\n",
    "                        if (((j+1) not in size_filter[i]) \n",
    "                        & ((j+1) not in landfall_filter[i]) \n",
    "                        & ((j+1) not in filter_list_1[i])\n",
    "                        & ((j+1) not in filter_list_2[i])\n",
    "                        & ((j+1) not in filter_list_3[i])\n",
    "                        & ((j+1) not in filter_list_4[i])\n",
    "                        & ((j+1) not in filter_list_5[i])):\n",
    "                            Count += 1\n",
    "                            date_text = str(ivt[i].coord('time'))[10:20]\n",
    "                            time_text = str(ivt[i].coord('time'))[21:23]\n",
    "                            year = date_text[0:4]\n",
    "                            month = date_text[5:7]\n",
    "                            day = date_text[8:10]\n",
    "                            time = time_text\n",
    "                            length = str(round(axis_length_list[i][j], -1))[:-1][:-1]\n",
    "                            width = str(round(object_width_list[i][j], -1))[:-1][:-1]\n",
    "                            mean_ivt = (str(round(mean_ivt_magnitude_list[i][j], \n",
    "                                                          0))[:-1][:-1])\n",
    "                            mean_ivt_direction = (str(round(mean_ivt_direction_list[i][j], \n",
    "                                                          1))[:-1][:-1])\n",
    "                            landfall_ivt = (str(round(landfall_ivt_magnitudes[i][j], \n",
    "                                                          0))[:-1][:-1])\n",
    "                            landfall_ivt_direction = (str(round(landfall_ivt_directions[i][j], \n",
    "                                                          1))[:-1][:-1])\n",
    "                            with open('{}\\\n",
    "/ar_characteristics/ar_characteristics.csv'.format(ar_dir), 'a', newline='') as f:\n",
    "                                thewriter = csv.writer(f)\n",
    "                                thewriter.writerow(['{}'.format(year), \\\n",
    "                                                    '{}'.format(month), \\\n",
    "                                                    '{}'.format(day), \\\n",
    "                                                    '{}'.format(time), \\\n",
    "                                                    '{}'.format(Count), \\\n",
    "                                                    '{}'.format(length), \\\n",
    "                                                    '{}'.format(width), \\\n",
    "                                                    '{}'.format(mean_ivt), \\\n",
    "                                                    '{}'.format(mean_ivt_direction), \\\n",
    "                                                    '{}'.format(landfall_ivt), \\\n",
    "                                                    '{}'.format(landfall_ivt_direction)])\n",
    "        # -------------------- Save Filtering Statistics ---------------------\n",
    "        # --------------------------------------------------------------------\n",
    "        if include_filtering_data == 1:\n",
    "            num_landfall_filter = []\n",
    "            num_size_filter = []\n",
    "            num_filter_1 = []\n",
    "            num_filter_2 = []\n",
    "            num_filter_3 = []\n",
    "            num_filter_4 = []\n",
    "            num_filter_5 = []\n",
    "            [num_landfall_filter.append(len(x)) for x in landfall_filter]\n",
    "            [num_size_filter.append(len(x)) for x in size_filter]\n",
    "            [num_filter_1.append(len(x)) for x in filter_list_1]\n",
    "            [num_filter_2.append(len(x)) for x in filter_list_2]\n",
    "            [num_filter_3.append(len(x)) for x in filter_list_3]\n",
    "            [num_filter_4.append(len(x)) for x in filter_list_4]\n",
    "            [num_filter_5.append(len(x)) for x in filter_list_5]\n",
    "            num_ob_0 = np.sum(num_ob_list)\n",
    "            num_ob_1 = num_ob_0 - np.sum(num_landfall_filter) - np.sum(num_size_filter)\n",
    "            num_ob_2 = num_ob_1 - np.sum(num_filter_1) \n",
    "            num_ob_3 = num_ob_2 - np.sum(num_filter_2) \n",
    "            num_ob_4 = num_ob_3 - np.sum(num_filter_3)\n",
    "            num_ob_5 = num_ob_4 - np.sum(num_filter_4)\n",
    "            num_ob_6 = num_ob_5 - np.sum(num_filter_5)\n",
    "            with open('{}\\\n",
    "filtering_data/filtering_data.csv'.format(ar_dir), 'a', newline='') as f:\n",
    "                thewriter = csv.writer(f)\n",
    "                thewriter.writerow(['{}'.format(year), \\\n",
    "                                    '{}'.format(month), \\\n",
    "                                    '{}'.format(num_ob_0), \\\n",
    "                                    '{}'.format(num_ob_1), \\\n",
    "                                    '{}'.format(num_ob_2), \\\n",
    "                                    '{}'.format(num_ob_3), \\\n",
    "                                    '{}'.format(num_ob_4), \\\n",
    "                                    '{}'.format(num_ob_5), \\\n",
    "                                    '{}'.format(num_ob_6)])\n",
    "        # --------------------------------------------------------------------\n",
    "        # --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
